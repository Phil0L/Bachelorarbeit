\chapter{Verwandte Arbeiten} % Related Work

Zunächst sind hier natürlich die zwei Arbeiten zu nennen, auf denen diese Arbeit hier basiert.
Dies ist einmal `BPMN diagram generation with ChatGPT' von Weidl~\cite{weidl2024bpmngen}
und `Enhancing BPMNGen: Improving LLM-based BPMN 2.0 Process Model Generation through 
Natural Language Processing' von Shi~\cite{shi2025bpmngen}.
Die genannten zwei Arbeiten bilden die Grundlage für dieses Arbeit.

\paragraph{ProMoAI}
Es existieren auch andere ähnliche Projekte, welche Prozessmodelle mit Hilfe von
LLMs erstellen.
Dazu gehört das Projekt ProMoAI
\footnote{\url{https://promoai.streamlit.app/}}
von Kourani et al.~\cite{kourani2024promoai} an der RWTH Aachen University.
ProMoAI setzt mehrere Prompting-Strategien ein, um Prozessmodelle aus Text zu erzeugen. 
Dazu gehört Role Prompting, bei dem das LLM als Prozessexperte und Prozessowner 
eingesetzt wird, sowie Few-Shot-Prompting, bei dem Beispielmodelle vorgegeben werden, 
damit das LLM typische Muster lernt. 
Zusätzlich nutzt ProMoAI Negative Prompting, um häufige Modellierungsfehler explizit zu 
vermeiden. 
Ein wichtiger Unterschied zu dieser Arbeit ist die Fokussierung auf die
von Kourani et al.\ selbst entwickelte Modellierungssprache POWL~\cite{kourani2023powl}, 
deren Struktur und klar definierte Operatoren dazu dienen, dass das LLM 
Prozessmodelle in einem gut überprüfbaren Format generiert.

\paragraph{AutoBPMN.AI}
Ein anderes Projekt ist AutoBPMN.AI\footnote{\url{https://autobpmn.ai/}}
von Klievtsova et al.~\cite{klievtsova2015autobpmnai} an der Technischen Universität München.
Bei diesem Projekt steht auch, wie bei BPMNGen, die konversationelle Modellierung im 
Vordergrund.
AutoBPMN.AI erstellt oder updatet Prozessmodelle in einem iterativen Austausch 
zwischen Nutzer und einem LLM, ähnlich wie bei dem Projekt dieser Arbeit.
Hierbei kann an den Chatbot entweder eine Prozessbeschreibung oder eine 
Prozessbeschreibung inkl.\ bereits erstelltem Prozessmodell geschickt werden, worauf mit einem
Prozessmodell geantwortet wird.
Es werden allerdings nicht BPMN 2.0 Prozessmodelle implementiert, sondern Graphen in der 
Software CPEE~\footnote{\url{https://cpee.org/index.php?t=cpee}}.
Für die KI wird allerdings so, wie auch bei BPMNGen, ein anderes Format für die KI benutzt.
AutoBPMN.AI setzt hier auf Mermaid\footnote{\url{https://mermaid.js.org/}}.
Dieses Format könnte auch für BPMN-Gen interessant sein.
In den veröffentlichten Arbeiten werden die genauen Prompting-Strategien jedoch nur sehr 
begrenzt beschrieben, sodass sich hier nur schwer konkrete Strategien ableiten lassen.

\paragraph{NaLa2BPMN}
Ein weiteres relevantes Projekt ist NaLa2BPMN\footnote{\url{https://nala2bpmn.bonitapps.com/}},
von Nour Eldin et al.~\cite{noureldin2024nala2bpmn, noureldin2024hybridnala2bpmn} 
das ebenfalls LLMs zur automatischen Erzeugung von BPMN-Modellen aus Text nutzt. 
NaLa2BPMN verfolgt einen hybriden Ansatz, bei dem der Gesamtprozess 
in zwei strukturierte Schritte zerlegt wird. 
Zunächst wird das LLM eingesetzt, um den Nutzertext zu analysieren, zu verbessern und fehlende 
Details zu ergänzen.
Anschließend werden Aktivitäten, Events, Abhängigkeiten und Verzweigungen von dem LLM
identifiziert und als Graph in Textform dargestellt. 
Als zweiter Schritt baut ein algorithmischer, deterministischer Teil aus den extrahierten 
Informationen das BPMN-Modell.
Der Algorithmus unterstütz dabei Techniken wie Loop-Filtering, Split \& Join Discovery und
Loop Construction, welche Fehler entfernen können und die Qualität verbessern.
Laut einer Qualitätsstudie erzeugt NaLa2BPMN bessere Diagramme als ProMoAI~\cite{noureldin2024hybridnala2bpmn}.

\paragraph{LLM4PM}
Ein weiteres aktuelles Projekt ist LLM4PM von Ziche et al.~\cite{ziche2024llm4pm}, 
das in einer realen 
Unternehmensumgebung untersucht, wie LLMs zur Unterstützung der Prozessmodellierung 
eingesetzt werden können. 
Hierbei wurde der LLM-gestützte Chatbot PRODIGY 
entwickelt, um Prozessmodellierer bei der Erstellung von Prozessdiagrammen 
zu unterstützen. 
Der Ansatz nutzt dialogorientiertes Prompting, bei dem Nutzer in natürlicher Sprache 
Anfragen an das System stellen und das LLM schrittweise Rückfragen und Modellteile 
generiert, die in bestehende Modellierungswerkzeuge übernommen werden 
können. 
Hierbei ist das System sehr ähnlich wie der in dieser Arbeit verwendete Chain-of-Thought
Ansatz, mit dem Unterschied, dass PRODIGY mehr darauf ausgelegt ist, einzelne Elemente des
Prozessdiagramms zu optimieren, als vollständige Diagramme zu erzeugen.
Ein zentrales Element bei LLM4PM ist die Integration unternehmensspezifischer Dokumentation, 
die über Retrieval-Augmented Generation eingebettet wird, 
um das LLM mit organisationsspezifischem Kontextwissen zu versorgen und die Qualität der 
generierten Modelle zu verbessern. 
Dadurch zielt LLM4PM weniger auf die direkte automatische Generierung vollständiger 
BPMN-Modelle ab, sondern eher auf eine assistierende, interaktive 
Modellierungsunterstützung in realen Unternehmensumgebungen.
PRODIGY selber kann keine Diagramme erstellen, sondern erstellt formatierten Klartext, welcher von 
dem Tool BPMN Sketch miner\footnote{\url{https://www.bpmn-sketch-miner.ai/}}
interpretiert und in elementare Diagramme umgesetzt werden kann.

\paragraph{BPMN-Chatbot++}
Ein weiteres relevantes Projekt ist der BPMN-Chatbot++ von Köpke und Safan~\cite{koeppke2025BPMNChatbotPP},
ein dem hier vorgestellten BPMN-Gen sehr ähnliches Projekt, das erstmals auf der
BPM-Konferenz 2024~\cite{koeppke2024NLP4BPM} präsentiert und anschließend weiterentwickelt wurde.
Im Rahmen dieses Projekts entstand außerdem eine React-basierte Anwendung~\cite{koeppke2024BPMNChatbot}
\footnote{\url{https://bpmnchatbot.aau.at/pubserv/BPMN-Chatbot-Beta/}},
die zur Generierung von BPMN-2.0-Diagrammen mit BPMN-Chatbot++ genutzt werden kann.
Zwischen BPMNGen und BPMN-Chatbot++ bestehen einige Parallelen. 
Dazu zählt die dynamische
Prompt-Generierung, durch die das Modell zum Beispiel aufgefordert werden kann, konkrete Fehler im
Diagramm zu beheben. Ebenso wird ein Zwischenmodell in JSON erzeugt, in
dem die KI antworten soll und das anschließend mittels Model2Model-Transformation in BPMN-XML
überführt wird. Es wurde zunächst Zero-Shot-Prompting ausprobiert aber dann auf
Few-Shot-Prompting umgestellt. 
Auch das Schema-Constraining zur Validierung des generierten
JSON-Modells wird wie bei BPMN-Gen verwendet.
Ein wesentlicher Aspekt des BPMN-Chatbot++ sind die integrierten Model checking components~\cite{koeppke2025BPMNChatbotPP, koeppke2025ERForum}. 
Diese sind direkt auf dem
Zwischenmodell implementiert und ermöglichen es konkrete Fehler
zu erkennen. 
Implementiert wurden hierfür sowohl der Process Application Validator (vPAV)
~\cite{schneid2021data} als auch der S$^3$ checker~\cite{corradini2020correctness}.
Durch deren Rückmeldungen erhalten sowohl der Nutzer als auch die KI eine Übersicht, 
welche Probleme im aktuellen Diagramm noch bestehen. 
Durch diese Validatoren kann die Qualität der Diagramme Schritt für Schritt verbessert werden, 
da die KI anhand der gefundenen Fehler auch semantische Fehler korrigieren kann.
