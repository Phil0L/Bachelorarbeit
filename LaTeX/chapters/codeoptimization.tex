\chapter{Umstrukturierung und Innovation}

Als erstes gilt es herauszufinden welcher Teil des Code, der zuständig für das prompting ist, wie verbessert werden kann.
Das Projekt von TBA benutzt zur Erstellung von BPMN Diagrammen die OpenAI API und verwendet hier die bereitgestellte 
Technologie der Assistants.

\section{Generelle Umstrukturierungen}

Während der Code gut für seinen (bisherigen) speziellen Anwendungsfall ist, können hier einige Verbesserungen gemacht werden.

\subsection{Objektorientierter Ansatz}

Das Zeil ist es, den Code einfach erweiterbar und wartbar zu machen.
Hierfür ist es wichtig, den code möglichst schnell an Änderungen der OpenAI Api anpassen zu können.
Um das zu erreichen wird ein Objektorientierter Ansatz gewählt.
Die objektorientierte Programmierung bietet für den Aufbau des Prompting-Codes viele Vorteile und macht die Entwicklung 
langfristig übersichtlicher und wartbarer. 
Wir erstellen eine abstrakte Klasse `ai.ts' welche die gesamte Logik des Prompting beinhält und eine Klasse `openai.ts' 
welche von der AI Klasse erbt.
Die OpenAi Klasse muss nun nur noch Methoden implementieren, welche konkret auf die aktuelle version der API angepasst sind.
Durch die Verwendung von abstrakten Methoden wie generateContent(), createTitle() oder processResponse() wird sichergestellt, 
dass jede konkrete Implementierung dieselbe Schnittstelle einhält, 
aber ihre eigenen internen Abläufe definieren kann. 
Dies erleichtert den Austausch und die Erweiterung von Modellen, ohne den restlichen Code verändern zu müssen. 
Darüber hinaus werden wiederkehrende Prozesse, etwa das Speichern von Verläufen, das Verarbeiten von Antworten 
oder die Konvertierung zwischen Formaten, zentral in der Basisklasse gekapselt. 
Falls sich die API ändert, kann dies nun einfach in der Erbenden Klasse angepasst werden, ohne die dahinterliegenden Logik verändern zu müssen.

So sieht nun in abgespeckter Variante die Klasse für die OpenAI API aus.
Es gibt eine Methode \mintinline{typescript}{mapPromptInput();} um den Prompt in das richtige Format der API zu bringen,
\mintinline{typescript}{generateContent();} um den eigentlichen API aufruf durchzuführen und \mintinline{typescript}{preocessResponse();}
um die Antwort der API auszulesen.\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
export class ChatGPT extends Ai {
  openai = new OpenAI({
    apiKey: OPENAI_API_KEY,
  });
  assist = await openai.beta.assistants.retrieve("asst_...");

  protected mapPromptInput(input) {
    return {
      input: input.prompt,
      model: this.model,
    };
  }

  protected async generateContent(input) {
    return await openai.beta.threads.runs.createAndPoll(
      thread_id, 
      { assistant_id: assist.id },
      { role: "user", content: input }
    );
  }

  protected processResponse(response) {
    return response.output_text.toString();
  }
}
\end{minted}
\end{samepage}

\subsection{Von Assistants zu Responses}

Die Änderungen welche im vorherigen Kapitel beschrieben wurden, zeigen gleich ihren Effekt, da OpenAI ankündigt ihre 
Assistants API einstellen zu wollen.
Sie emfehlen einen Umzug zu ihrer neuen Responses API.
Dies ist nun recht einfach umzusetzten, da wir nur die elementaren Methoden der API ändern müssen. 
So sieht nun die neue Methode \mintinline{typescript}{generateContent();} aus:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
protected async generateContent(input) {
  return this.openai.responses.create(input);
}
\end{minted}
\end{samepage}

Einer der zentralen Unterschiede zwischen der Assistants- und der Responses-API besteht darin, 
dass die System-Instructions bei der Verwendung der Responses-API manuell übergeben werden müssen. 
Dadurch ist es notwendig, die entsprechenden Anweisungen bei jeder Anfrage erneut mitzusenden. 
Dieser Umstand bringt jedoch nicht nur zusätzlichen Aufwand mit sich, sondern eröffnet auch neue Möglichkeiten: 
Die Instructions können flexibel und situationsabhängig angepasst werden, wodurch sich das Verhalten des Modells 
dynamisch steuern lässt.
Im folgenden Abschnitt wird gezeigt, wie dieser Ansatz weiter verbessert und effizienter gestaltet werden kann.

\subsection{Verbesserung der instructions}

Da die Instructions nun manuell mit jeder Anfrage übergeben werden, bietet sich die Möglichkeit, deren Aufbau 
gezielt zu optimieren. 
Ziel dieser Optimierung ist es, die Anzahl der benötigten Input-Tokens zu reduzieren, ohne dabei Qualität einzubüßen. 
Im besten Fall wird die Ausgabequalität sogar verbessert.
Der Assistant erhält als Grundlage zwei PDF-Dateien, die BPMN-Diagramme im Detail beschreiben, sowie zwei Textdateien: 
eine mit der Definition des verwendeten JSON-Formats und eine mit allgemeinen Regeln zum Aufbau der Diagramme. 
Die beiden PDF-Dokumente umfassen zusammen mehr als 10 MB und über 100 Seiten Text. 
Da ChatGPT bereits ein solides Grundverständnis von BPMN-Diagrammen besitzt, werden diese umfangreichen Dateien aus 
den Instructions entfernt. Mehrere Tests zeigen, dass sich diese Reduktion nicht negativ auf die Ergebnisqualität auswirkt. 
Dadurch lassen sich eine große Zahl an Tokens sowie Rechenzeit und Kosten einsparen.

Die beiden verbliebenen Textdokumente werden anschließend zusammengeführt, überarbeitet und in ein einheitliches, 
strukturiertes Format gebracht. 
Alle Regeln sind in einer geordneten Liste zusammengefasst und durch sogenanntes structured prompting klarer und 
maschinenlesbarer gestaltet. 
Ergänzend werden den Instructions zwei illustrative Beispiele hinzugefügt:
Zum einen ein minimales Beispiel, das den grundsätzlichen Aufbau des JSON-Formats verdeutlicht und die 
obligatorischen Elemente zeigt. 
Zum anderen ein umfangreicheres, praxisnahes Beispiel, das ein vollständiges BPMN-Diagramm mit allen relevanten Komponenten 
abbildet. 
Diese Kombination sorgt dafür, dass der Assistant sowohl einfache als auch komplexe Diagramme präzise interpretieren 
und reproduzieren kann.


\section{Formatauswahl}

Bisher wird die KI angewiesen, das Diagramm in einem eigens definierten JSON-Format zu erzeugen. 
Dieses Format wurde jedoch speziell für diesen Anwendungsfall entworfen und existiert in dieser Form nicht offiziell.
Entsprechend konnte das Modell während des Trainings kein Vorwissen darüber erwerben, sondern muss das Format 
ausschließlich auf Grundlage der bereitgestellten Instructions erlernen. 
Dadurch besteht die Möglichkeit, dass Fehler auftreten, etwa dann, wenn die Anweisungen unvollständig sind oder dem Modell 
bestimmte Kontextinformationen fehlen.

Um dieses Problem zu vermeiden, wird künftig die Option ergänzt, dass die KI ihre Ausgabe auch direkt im offiziellen 
Standardformat erzeugen kann. 
Das weltweit am häufigsten verwendete Austauschformat für BPMN-Diagramme ist XML, 
zu dem umfangreiche Dokumentation und etablierte Werkzeuge existieren. 
Dennoch bietet das eigens entwickelte JSON-Format einen entscheidenden Vorteil: 
Es besitzt eine deutlich höhere Informationsdichte und lässt sich dadurch kompakter und effizienter verarbeiten. 
Beide Formate haben somit ihre jeweiligen Stärken und Einsatzgebiete.

\begin{table}[H]
  \centering
  \renewcommand{\arraystretch}{1.2}
  \begin{tabular}{|p{2cm}|p{5.5cm}|p{5.5cm}|}
    \hline
    \textbf{Kriterium} & \textbf{JSON-Format} & \textbf{XML-Format} \\ \hline
    \textbf{Vorteile} &
    hohe Informationsdichte, geringer Tokenverbrauch, schnelle Generierung. &
    Standardisiert, gut dokumentiert, weit verbreitet, einfachere Instructions \\ \hline
    \textbf{Nachteile} &
    Kein Standard, Lernaufwand, komplizierter Konvertierungsalgorythmus. &
    hoher Tokenverbrauch, umfangreiche Syntax, unübersichtlicher, mehr Kosten, längere Generierung. \\ \hline
  \end{tabular}
  \caption{Vergleich der Vor- und Nachteile der unterstützten Ausgabeformate}
\end{table}

Für die Weiterentwicklung ist ein flexibles System das Ziel, das eine dynamische Auswahl des Ausgabeformats besitzt. 
Dadurch kann der Nutzer selbst entscheiden, welches Format im jeweiligen Anwendungsfall die besseren Ergebnisse liefert. 
Da sich die Formatwahl ähnlich wie die Wahl des verwendeten Modells direkt auf die Qualität der Ergebnisse auswirkt, 
wird die Auswahlmöglichkeit direkt in die Modellkonfiguration integriert. 
So kann beispielsweise zwischen Varianten wie `gpt-4.1-mini (xml)' und `gpt-4.1-mini (json)' gewählt werden. 
Wird kein Format angegeben, erfolgt die Ausgabe standardmäßig im XML-Format.

Eine Anfrage sieht damit z.B. folgendermaßen aus:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{json}
// POST /threads
{ 
  "inputString": "Bitte generiere mir ein BPMN Diagram, 
      welches den Ablauf in einem Restaurant zeigt", 
  "model": "gpt-5 (xml)",
}
\end{minted}
\end{samepage}

Bei einer Anfrage kann dann die jeweilige AI über eine Map 

\mintinline{typescript}{const availableGPTs: Map<string, Ai>} 

zugeordnet werden, welche die Anfrage bearbeitet.

// TODO: update neuerungen noch machen


\section{Dateien}

Um die Qualität des Promptings weiter zu verbessern, soll eine Funktionalität implementiert werden, 
die es ermöglicht, auch Dateien direkt an die KI zu übermitteln. 
Dabei steht im Vordergrund, dass das Verfahren sowohl im Frontend als auch im Backend möglichst 
unkompliziert umgesetzt werden kann. 
Es soll keine aufwendigen oder zeitraubenden Konvertierungen erfordern und eine breite Auswahl an 
Dateitypen unterstützen, um die Nutzung so flexibel wie möglich zu gestalten.
Nach einer Analyse der OpenAI-Dokumentation unter
\url{https://platform.openai.com/docs/guides/images-vision?api-mode=responses&format=base64-encoded#analyze-images}
zeigt sich, dass die einfachste und zugleich effizienteste Methode zur Dateiübertragung die 
Verwendung einer Base64 Data URL ist. 
Diese Variante bietet eine einfache Möglichkeit, Binärdaten wie Bilder oder Dokumente direkt 
in Textform zu kodieren und zu übermitteln, ohne zusätzliche Infrastruktur oder spezielle 
Upload-Mechanismen zu benötigen.

Eine Base64 Data URL ist im eine Textdarstellung einer Datei, die direkt in eine URL eingebettet wird. 
Dabei werden die ursprünglichen Binärdaten in ein spezielles Textformat namens Base64 umgewandelt. 
Diese kodierten Daten beginnen typischerweise mit einer Kennzeichnung wie data:image/png;base64,\dots 
und enthalten danach die eigentlichen kodierten Inhalte. 
Der große Vorteil liegt darin, dass der Browser oder die API diesen Text automatisch wieder in die 
ursprüngliche Datei zurückwandeln kann. Auf diese Weise lassen sich Dateien direkt in 
JSON API-Anfragen integrieren, ohne dass zusätzliche Dateipfade, Server oder externe Speicherorte 
erforderlich sind. 
Dieses Verfahren ist daher besonders gut geeignet, um eine einfache, schnelle und universell 
kompatible Dateiübertragung zu ermöglichen.
Dadurch, dass die Datei nun einfach als String übergeben werden kann, können wir die Datei dem Body 
der Anfrage hinzufügen.

Eine Anfrage sieht damit z.B. folgendermaßen aus:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{json}
// POST /threads
{ 
  "inputString": "Bitte generiere mir ein BPMN Diagram, 
      welches den Ablauf in einem Restaurant zeigt", 
  "model": "gpt-5 (xml)",
  "file": "data:image/png;base64,A35ekZ...",
}
\end{minted}
\end{samepage}

Der string wird auf Validität geprüft\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
private checkBase64DataUrl(dataUrl: string): boolean {
  regex = /^data:([\w.+-]+\/[\w.+-]+)?;base64,[\w+\/]+=*$/;
  return regex.test(dataUrl);
}
\end{minted}
\end{samepage}

und dann im richtigen Format an die OpenAI API gesendet:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
const imageInstructions = {
  role: "user",
  content: [
    {
        type: "input_file",
        file_url: input.getFileDataUrl() as string,
    } as ResponseInputFile,
  ],
} as ResponseInputItem
\end{minted}
\end{samepage}

\section{Chain of Thought}

Um die Erzeugung und Interaktion rund um BPMN-Diagramme weiter zu verbessern, wird eine 
Technik implementiert, die als `Chain of Thought' bezeichnet wird. 
Dieses Verfahren ermöglicht es dem Modell, komplexere Denkprozesse intern nachzuvollziehen und 
schrittweise zu argumentieren, bevor eine Antwort erzeugt wird. 
Dadurch kann der Dialog natürlich und strukturiert verlaufen, da der Chatbot in der Lage ist, 
Zusammenhänge besser zu verstehen und über mehrere Gesprächsschritte hinweg Ergebnisse 
zu liefern.

Diese Erweiterung erlaubt es dem Nutzer, auf vielfältige Weise mit dem Chatbot zu interagieren: 
Es können Fragen gestellt, Ideen entwickelt, bestehende Diagramme erläutert oder 
Verbesserungsvorschläge erfragt werden. 
Der BPMN-Bot soll damit nicht nur ein Werkzeug für Diagrammerstellung bleiben, sondern sich zu einem 
vollwertigen, kontextbewussten Assistenten weiterentwickeln, der beim gesamten Modellierungsprozess 
unterstützt.

Darüber hinaus ist vorgesehen, dass der Chatbot selbstständig Rückfragen stellt, wenn bestimmte 
Angaben unvollständig, mehrdeutig oder widersprüchlich sind. 
So kann ein interaktiver Dialog entstehen, in dem beide Seiten aktiv zum Verständnis und zur Qualität 
der Diagrammerstellung beitragen. 
Um dies zu ermöglichen, benötigt der Chatbot Zugriff auf den bisherigen Gesprächsverlauf sowie auf 
den aktuellen Zustand des jeweiligen Diagramms. 
Nur durch diese Kontextkenntnis kann die KI präzise, nachvollziehbare und qualitativ hochwertige 
Antworten generieren.

\subsection{Implementierung eines neuen Modus}

Um die Erstellung von Diagrammen für den Nutzer nicht unnötig zu verkomplizieren,
bleibt die direkte Generierung eines BPMN-Diagramms weiterhin bestehen. 
Gleichzeitig soll jedoch mehr Flexibilität bei der Art der Interaktion geboten werden. 
Zu diesem Zweck wird der Anfrage ein zusätzlicher Parameter hinzugefügt, 
der das Antwortverhalten der KI steuert.

Über den Parameter \texttt{mode} kann festgelegt werden, in welchem Modus die
KI reagieren soll. 
Der bisherige Modus, bei dem ausschließlich das Diagramm
erzeugt wird, trägt nun die Bezeichnung \texttt{quick}. 
In diesem Modus erfolgt die Ausgabe direkt und ohne weiteren Dialog.

Der neu eingeführte Modus \texttt{detail} aktiviert den sogenannten
`Chain of Thought'-Ansatz. In diesem Modus verhält sich die KI dialogorientiert.
Sie kann Rückfragen stellen, Überlegungen anstellen oder alternative Vorschläge
anbieten, bevor das endgültige Diagramm erstellt wird. Dadurch entsteht eine
interaktive Konversation, die vor allem bei komplexeren Prozessen oder
unvollständigen Eingaben von Vorteil ist.

Eine Anfrage, die eine solche erweiterte Unterhaltung ermöglicht, könnte
beispielsweise folgendermaßen aussehen:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{json}
// POST /threads
{ 
  "inputString": "Bitte schlag drei Prozessbeschreibungen 
    vor, aus denen dann eine ausgewählt wird um ein Diagramm
    zu erstellen.", 
  "model": "gpt-5 (xml)",
  "mode": "detail",
}
\end{minted}
\end{samepage}

\subsection{Konversationskontext}

Da es nun darum geht ein Chat zu implementieren, bei dem die KI möglichst gut auf Nachrichten reagieren
kann, ist es wichtig, dass die KI zugriff auf vorherige Nachrichten sowie auf das Diagramm hat.
Wäre das nicht der Fall, könnte die KI keine Fragen über das Diagramm beantworten und auch keine 
richtige Unterhaltung führen, da immer nur die aktuelle Nachricht bereitgestellt wird.
Bei LLM Anbietern wie OpenAI ist es notwendig, dass die Nachrichten historie in der Anfrage 
mitgeschickt wird.

Hierfür müssen alle Nachrichten eines Theads aus der Datenbank geladen werden.
Die Nachrichten werden dann auf wesentliche gefiltert und auf ein kompaktes Foramt gebracht.
Die OpenAI Klasse muss dann nur noch die Nachrichten auf das gefoderte Format bringen und in der
Anfrage mitschicken.
Da die Anfagen an die KI immer komplexer werden, wird nun eine Klasse $PromptInput$ angelegt.
Diese Klasse beinhaltet alle Informationen welche der KI mitgesendet werden sollen.
Bei einer erstellung diese Objekt können alle Rohdaten wie Instructions, Dateien oder der Chatverlauf
übergebe werden, welche die Klasse dann automatisch formatiert.
Ein entscheidender Schritt hierbei ist es die Teile der Nachrichten zu entfernen, in denen die KI mit einem
Diagramm geantwortet hat.
Das ist wichtig, da die Diagramme viele Tokens beinhalten und eigentlich nur das aktuellste Diagram 
wichtig ist. Hier bei kann es aber auch sein, dass das Diagramm noch vom Nutzer bearbeitet wurde.
Um dies zu berücksichtigen sind die Diagramme nuicht Teil der Nachrichten, welche mitgesendet werden.
Die Implementierung der KI-Schnittstelle kann anschließend ein Objekt der Klasse \texttt{PromptInput} 
entgegennehmen. 
Dieses Objekt dient als zentrale Datenstruktur, über die alle für die Anfrage relevanten Informationen 
an das Modell übergeben werden. 
Mithilfe vordefinierter Hilfsmethoden lässt sich der Inhalt komfortabel in das gewünschte 
Eingabeformat konvertieren, sodass keine manuelle Aufbereitung mehr erforderlich ist.

Die Klasse \texttt{PromptInput} verfügt über folgende Attribute:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
export class PromptInput {
  instructions: string[];
  history: {role: "user" | "assistant", content: string}[];
  prompt: string;
  file?: ;
}
\end{minted}
\end{samepage}

Damit ist es möglich, bestehende Nachrichtenverläufe aus der Datenbank abzurufen und automatisch in 
das benötigte Format zu überführen. 
Die Klasse übernimmt hierbei die vollständige Strukturierung der Daten, sodass diese
für die Kommunikation mit der KI genutzt werden können:\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
const instructions = [formatInstructions, modeInstructions];
const chatsFromDB = getAllChatsFromDB(threadID);
new PromptInput(instructions, prompt, chatsFromDB, file);
\end{minted}
\end{samepage}

Das so erzeugte \texttt{PromptInput}-Objekt kann anschließend durch interne Methoden in das finale 
Format umgewandelt werden, das von der KI-Schnittstelle erwartet wird. 
Dadurch entsteht ein einheitlicher, wiederverwendbarer Datenfluss zwischen Anwendung, Datenbank und 
Modell, der die Wartung sowie zukünftige Erweiterungen vereinfacht.\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
protected mapPromptInput(input: PromptInput) {   
  [...]
  const historyInstructions = input.history.map((item) => {
    return {role: item.role, content: item.content};
  });
  return {
    input: [systemInstructions, historyInstructions, 
            userInstructions, fileInstructions],
    model: this.model,
  };
}
\end{minted}
\end{samepage}

Darüber hinaus soll künftig auch die jeweils aktuellste Version des Diagramms an die Anfrage angehängt 
werden. 
Auf diese Weise erhält die KI den vollständigen Kontext und kann das bestehende Diagramm nicht nur 
bearbeiten, sondern auch inhaltliche Fragen dazu beantworten.

Da das aktuelle Diagramm nicht Bestandteil des eigentlichen Nachrichtenverlaufs ist, wird es in den 
sogenannten `System Instructions' hinterlegt. 
Diesen Instruction Block wird nun als `Update Instructions' bezeichnet und enthält stets die zuletzt 
gespeicherte Version des Diagramms. 
Die entsprechenden Daten werden automatisch aus der Datenbank geladen und vor dem Absenden der Anfrage 
in die System Instructions eingefügt.

Durch dieses Verfahren ist sichergestellt, dass die KI bei jeder Interaktion auf dem neuesten Stand 
bleibt und Änderungen im Diagramm jederzeit konsistent nachvollziehen kann.\\

\begin{samepage}
\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{typescript}
protected updateInstructions(threadID: string, format: format){
  const diagram = getLatestDiagramFromDB(threadID);
  return [`The The following diagram has already been created:
    ${format == "xml" ? diagram?.xml : diagram?.json}`]
}
\end{minted}
\end{samepage}

Damit hat die KI nun alle Informationen die sie benötigt um eine Konversation führen zu können.

\subsection{Konversationen}

Für eine vollständige Konversation benötigt die KI nun aber noch Anweisungen.
Dafür werden der KI noch die sogenannten $modeInstructions$ bereitgestellt.
Diese sehen zunächst so aus:\\

\begin{minted}[frame=single, framesep=2pt, linenos, fontsize=\small, style=vs]{text}
[Output Language depends on prompt language]

Alternative to creating a bpmn diagram you may ask any 
questions you feel like need answering to create the best bpmn 
diagram.
If you do not have any questions any more, please write a 
quick summary of the agreed diagram before creating the bpmn 
xml.
If the initial prompt is really basic provide the user with a 
creative scenario summary.

Once the user has agreed on a summary, Do no longer answer in 
plain text but only in bpmn xml.
If you want to provide questions, summary or any other type of 
text, that is not a diagram. Do not use JSON or XML. 
Only plain Text!
\end{minted}

Diese Instructions werden nur mitgesendet, falls der $detail$ modus genutzt wird.

Es ist nun eine Konversation möglich.

Wenn man den Bot nun fragt: ``Bitte schlag mir ein Diagramm vor'' antwortet dieser mit:

\setlist{nolistsep}
\noindent\fbox{
  \parbox{\textwidth}{
    Gerne, ich schlage Ihnen ein klassisches und leicht verständliches Szenario vor: 
    einen \textbf{Online-Bestellprozess}. 
    Dieses Diagramm würde die Interaktion zwischen einem Kunden und einem Online-Shop 
    darstellen und eignet sich gut, um grundlegende BPMN-Konzepte zu zeigen. 
    \textbf{Zusammenfassung des vorgeschlagenen Diagramms:} 
    \begin{itemize}[noitemsep]
      \item \textbf{Beteiligte (Pools):}
        \begin{enumerate}[noitemsep]
          \item Kunde
          \item Online-Shop
        \end{enumerate}
      \item \textbf{Ablauf beim Kunden:}
        \begin{enumerate}[noitemsep]
          \item Der Prozess beginnt damit, dass der Kunde ein Produkt auswählt.
          \item Er gibt eine Bestellung auf, was eine Nachricht an den Online-Shop sendet.
          \item Danach wartet er auf die Bestellbestätigung.
          \item Anschließend wartet er auf die Versandbestätigung.
          \item Der Prozess endet, wenn der Kunde die Ware erhalten hat.
        \end{enumerate}
      \item \textbf{Ablauf im Online-Shop:}
      \begin{enumerate}[noitemsep]
        \item Der Prozess startet, sobald die Bestellung des Kunden eingeht.
        \item Die Bestellung wird geprüft.
        \item Eine Entscheidung (Gateway): Ist der Artikel verfügbar?
          \begin{itemize}[noitemsep]
            \item \textbf{Ja:} Die Bestellung wird bestätigt (Nachricht an den Kunden), 
              die Ware wird verpackt und versendet. 
              Eine Versandbestätigung wird an den Kunden gesendet.
            \item \textbf{Nein:} Die Bestellung wird abgelehnt (Nachricht an den Kunden) 
              und der Prozess endet. 
          \end{itemize}
        \item Nach dem Versand der Ware ist der Prozess für den Shop abgeschlossen.
      \end{enumerate}
    \end{itemize}
    Dieses Szenario zeigt die Zusammenarbeit zwischen zwei Teilnehmern, den Austausch von 
    Nachrichten und eine einfache Geschäftsentscheidung. 
    Sind Sie mit diesem Vorschlag einverstanden? 
    Falls ja, erstelle ich das entsprechende BPMN 2.0 XML für Sie.
  }
}

Man kann darauf antworten mit ``Ja, bitte generier mir das Diagramm genau so wie beschrieben''.
Der Bot versteht, dass er nun nicht antworten, sondern ein Diagramm erstellen soll.
Daher sendet er nun kein Klartext sondern direkt ein BPMN XML.
Dieses sieht folgendermaßen aus:

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{images/diagrams/diagram_1}
  \caption{\label{fig:diagram1}Beschreibung/Beschriftung des Bilds}
\end{figure}


Es fällt auf, dass der Bot das Gateway `Ist der Artikel verfügbar?' vergessen hat.
Dies ist allerdings kein Problem da das Diagramm nun weiter durch Prompts verbessern kann.
``Bitte bearbeite das Diagramm indem du das vergessene Gateway `Ist der Artikel verfügbar?' hinzufügst.''
Der Bot erkennt nun wieder, dass keine Textantwort gewünscht ist und beginnt mit der  
Übersendung des neuen Diagramms.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{images/diagrams/diagram_2}
  \caption{\label{fig:diagram1}Beschreibung/Beschriftung des Bilds}
\end{figure}



\section{Weitere Anbieter}

\subsection{Grok}

\subsection{Gemini}

\subsection{Claude}

\section{Streaming}

\section{Schema-Constraining}

\section{Evtl. Sampling}

\section{Evtl. Reflective Prompting}



