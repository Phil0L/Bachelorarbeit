% Encoding: UTF-8

@misc{wei2023chainofthought,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
  author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year={2023},
  eprint={2201.11903},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2201.11903}, 
}

@mastersthesis{weidl2024bpmngen,
  author       = {Weidl, Niklas},
  title        = {BPMN Diagram Generation with ChatGPT},
  school       = {Ulm University},
  type         = {Bachelor thesis},
  year         = {2024},
  address      = {Ulm, Germany},
  note         = {Submitted for the degree of Bachelor of Science (BSc) in Medieninformatik. Advisors: Prof. Dr. Manfred Reichert; Supervisor: Luca H{\"o}rner},
  email        = {niklas.weidl{\@}uni-ulm.de},
  matriculation= {1049104}
}

@mastersthesis{shi2025bpmngen,
  author       = {Shi, Zhe},
  title        = {Enhancing BPMNGen: Improving LLM-based BPMN 2.0 Process Model Generation through Natural Language Processing},
  school       = {Ulm University},
  type         = {Bachelor thesis},
  year         = {2025},
  address      = {Ulm, Germany},
  note         = {Submitted for the degree of Bachelor of Science (B.Sc) in Informatik. Advisor: Prof. Dr. Manfred Reichert; Supervisor: Luca H{\"o}rner},
  email        = {zhe.shiuni-ulm.de},
  matriculation= {1036630}
}

@inproceedings{costa2025llm4bpmngen,
  author       = {Costa, Ana and Wimmer, Alena and Pufahl, Luise},
  title        = {LLM4BPMNGen: A Tool for BPMN Generation with LLMs},
  booktitle    = {ER-Companion 2025: Companion Proceedings of the 44th International Conference on Conceptual Modeling, Industrial Track / ER Forum / 8th SCME / Doctoral Consortium / Tutorials / Project Exhibitions / Posters and Demos, Poitiers, France, October 20–23, 2025},
  editor       = {Patrick Marcel},
  year         = {2025},
  pages        = {333--337},
  publisher    = {CEUR Workshop Proceedings},
  volume       = {4099},
  address      = {Poitiers, France},
  issn         = {1613-0073},
  url          = {https://ceur-ws.org/Vol-4099/ER25_PAD_Costa.pdf},
  note         = {Open Access under CC BY 4.0}
}

@misc{omg2014bpmn2,
  author       = {Object Management Group},
  title        = {Business Process Model and Notation (BPMN), Version 2.0.2},
  month        = jan,
  year         = 2014,
  note         = {Normative specification},
  url          = {https://www.omg.org/spec/BPMN/2.0.2/}
}

@book{silver2011bpmnmethod,
  author    = {Bruce Silver},
  title     = {BPMN Method and Style, 2nd Edition, with BPMN Implementers Guide},
  publisher = {Cody-Cassidy Press},
  year      = 2011,
  isbn      = {9780982368114},
  note      = {Ein praxisorientierter Leitfaden zu BPMN 2.0}
}

@misc{openai2025responses,
  author       = {OpenAI},
  title        = {Migrate to the Responses API},
  month        = mar,
  year         = 2025,
  howpublished = {\url{https://platform.openai.com/docs/guides/migrate-to-responses}},
  note         = {Offizielle Ankündigung / Entwicklerblog}
}

@article{Zhao2023_LLM_Survey,
  title   = {A Survey of Large Language Models},
  author  = {Zhao, Wayne Xin and Liu, Jingyuan and Li, Zekun and others},
  journal = {arXiv preprint arXiv:2303.18223},
  year    = {2023}
}

@inproceedings{iclr2024streaming,
 author = {Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike },
 booktitle = {International Conference on Representation Learning},
 editor = {B. Kim and Y. Yue and S. Chaudhuri and K. Fragkiadaki and M. Khan and Y. Sun},
 pages = {21875--21895},
 title = {Efficient Streaming Language Models with Attention Sinks},
 url = {https://proceedings.iclr.cc/paper_files/paper/2024/file/5e5fd18f863cbe6d8ae392a93fd271c9-Paper-Conference.pdf},
 volume = {2024},
 year = {2024}
}

@misc{vaswani2023attentionneed,
  title={Attention Is All You Need}, 
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year={2023},
  eprint={1706.03762},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1706.03762}, 
}

@misc{fette2011sse,
  author       = {Fette, Ian and Melnikov, Alexey},
  title        = {HTML5 Server-Sent Events},
  year         = {2011},
  howpublished = {\url{https://www.w3.org/TR/eventsource/}},
  note         = {W3C Recommendation}
}

@misc{rfc2397,
  author       = {{D. Connolly and L. Masinter}},
  title        = {RFC 2397: The ``data'' URL Scheme},
  year         = {1998},
  howpublished = {\url{https://www.rfc-editor.org/rfc/rfc2397.html}},
  note         = {W3C / IETF Standard},
  month        = jul
}

@misc{rfc4648,
  author       = {{T. D. Hansen and P. Hoffman and A. Malhotra}},
  title        = {RFC 4648: The Base16, Base32, and Base64 Data Encodings},
  year         = {2006},
  howpublished = {\url{https://www.rfc-editor.org/rfc/rfc4648.html}},
  note         = {IETF Standard},
  month        = oct
}

@misc{zhao2024factandreflection,
  title={Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models}, 
  author={Xinran Zhao and Hongming Zhang and Xiaoman Pan and Wenlin Yao and Dong Yu and Tongshuang Wu and Jianshu Chen},
  year={2024},
  eprint={2402.17124},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2402.17124}, 
}

@misc{openai2022chatgpt,
  author       = {{OpenAI}},
  title        = {ChatGPT ist da},
  year         = {2022},
  month        = nov,
  day          = 30,
  howpublished = {\url{https://openai.com/de-DE/index/chatgpt/}},
  note         = {Offizielle Ankündigung / Produktseite}
}


@article{klievtsova2015autobpmnai,
  title = "AutoBPMN.AI: Conversational Process Modeling and Automation",
  abstract = "We demonstrate the text-based modeling and redesign of processes in the process execution environment of the Cloud Process Execution Engine (CPEE) based on iterative conversations with an LLM such as gemini or gpt. The input can be text and an empty model as well as text and an existing model. The output is a newly created or redesigned process model in executable format, i.e., based on abstract syntax trees and displayed in BPMN-like fashion, exploiting the automatic layout capabilities of the CPEE. The tool is demonstrated for different scenarios such as the creation and redesign of the process models, as well as the subsequent process model execution.",
  author = "Nataliia Klievtsova and Matthias Ehrendorfer and Juergen Mangler and Stefanie Rinderle-Ma",
  note = "Publisher Copyright: {\textcopyright} 2025 Copyright for this paper by its authors.; Best Dissertation Award, Doctoral Consortium, and Demonstration and Resources Forum at 23rd International Conference on Business Process Management, BPM-D 2025 ; Conference date: 31-08-2025 Through 05-09-2025",
  year = "2025",
  language = "English",
  volume = "4032",
  pages = "304--311",
  journal = "CEUR Workshop Proceedings",
  issn = "1613-0073",
  publisher = "CEUR-WS",
}

@inproceedings{kourani2024promoai,
  title     = {ProMoAI: Process Modeling with Generative AI},
  author    = {Kourani, Humam and Berti, Alessandro and Schuster, Daniel and van der Aalst, Wil M.P.},
  booktitle = {Proceedings of the Thirty-Third International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Kate Larson},
  pages     = {8708--8712},
  year      = {2024},
  month     = {8},
  note      = {Demo Track},
  doi       = {10.24963/ijcai.2024/1014},
  url       = {https://doi.org/10.24963/ijcai.2024/1014},
}




@Comment{jabref-meta: databaseType:bibtex;}
